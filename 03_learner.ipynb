{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev import *\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import math\n",
    "# import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, OneCycleLR\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AverageMeter:\n",
    "    \n",
    "    def __init__(self, store_vals=False, store_avgs=False):\n",
    "        self.store_vals = store_vals\n",
    "        self.store_avgs = store_avgs\n",
    "        if store_vals: self.values = []\n",
    "        if store_avgs: self.avgs = []\n",
    "        self.sum, self.n, self.avg = 0, 0, None\n",
    "        \n",
    "    def update(self, v):\n",
    "        if self.store_vals: self.values.append(v)\n",
    "        self.n += 1\n",
    "        self.sum += v\n",
    "        self.avg = self.sum/self.n\n",
    "        \n",
    "    def reset(self):\n",
    "        if self.store_avgs and self.avg: self.avgs.append(self.avg)\n",
    "        self.sum, self.n, self.avg = 0, 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def accuracy_binary(pred, targ):\n",
    "    return ((pred>0).float() == targ).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Callback:\n",
    "    def __init__(self, learn):\n",
    "        self.learn = learn\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "class TrainEvalCallback(Callback):\n",
    "    \n",
    "    def before_train(self):\n",
    "        self.learn.model.train()\n",
    "        self.learn.training = True\n",
    "    \n",
    "    def before_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.learn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "class SaveModelCallback(Callback):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.random.normal(size=(16*100, 10)).astype(np.float32)\n",
    "data_valid = np.random.normal(size=(16*100, 10)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data\n",
    "        self.y = data.sum(axis=1, keepdims=True)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(DS(data_train), 16)\n",
    "valid_dl = DataLoader(DS(data_valid), 16)\n",
    "dls = [train_dl, valid_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10, 10),\n",
    "                      nn.BatchNorm1d(10),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1]), torch.Size([16, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(x)\n",
    "pred.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7175, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCEWithLogitsLoss()(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wd_param_groups(model:nn.Module, wd:float):\n",
    "    decay, no_decay = [], []\n",
    "    for n, c in model.named_children():\n",
    "        if n == 'stem':\n",
    "            \n",
    "            no_decay += [p for p in c.parameters() if p.requires_grad]\n",
    "        else:\n",
    "            no_decay += [p for p in c.parameters() if (p.requires_grad and len(p.shape)==1)]\n",
    "            decay += [p for p in c.parameters() if p.requires_grad and len(p.shape)!=1]\n",
    "    params = [\n",
    "            {\"params\": decay, \"weight_decay\": wd},\n",
    "            {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn4tab.model import TabularModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnn = TabularModel([10,10], ((5,5), (4,4)), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (stem): TabInputBlock(\n",
       "    (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (embs): ModuleList(\n",
       "      (0): Embedding(5, 5)\n",
       "      (1): Embedding(4, 4)\n",
       "    )\n",
       "  )\n",
       "  (lins): Sequential(\n",
       "    (0): LinearBlock(\n",
       "      (m): Sequential(\n",
       "        (0): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=11, out_features=10, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (m): Sequential(\n",
       "        (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): LinearBlock(\n",
       "      (m): Sequential(\n",
       "        (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 2.7277e-01, -2.2471e-01,  2.6523e-01,  6.0695e-02, -2.5695e-01,\n",
       "             9.6278e-02,  1.2022e-01, -1.7679e-01, -1.6692e-01,  2.2691e-01,\n",
       "            -2.2678e-01],\n",
       "           [ 5.4562e-02,  2.7151e-01,  1.9484e-01, -1.3532e-01, -1.0771e-01,\n",
       "            -2.6080e-02, -1.0610e-01,  1.2190e-01, -2.8229e-04,  2.8142e-01,\n",
       "            -1.1737e-01],\n",
       "           [-4.7730e-02, -2.9663e-01,  1.9810e-01,  2.2263e-01,  1.9223e-01,\n",
       "             1.6017e-01,  1.0125e-01, -1.9813e-01, -5.7727e-02, -9.3859e-02,\n",
       "            -9.6990e-02],\n",
       "           [ 1.8757e-01, -2.6832e-01,  2.9684e-01, -1.5653e-01, -1.3973e-01,\n",
       "            -2.1311e-01, -1.3471e-01,  1.5990e-02, -1.3583e-01,  1.6816e-01,\n",
       "             1.7504e-01],\n",
       "           [-6.1790e-02, -2.0111e-01,  7.7752e-03, -1.6553e-01,  8.6983e-02,\n",
       "             2.0088e-01,  4.2001e-02, -8.5758e-03,  2.3476e-02,  2.3230e-02,\n",
       "             2.1135e-01],\n",
       "           [ 1.1087e-01, -2.8298e-01, -6.6622e-02,  1.8854e-02, -4.8628e-02,\n",
       "            -2.7107e-02,  2.2004e-02, -1.7098e-01,  2.3382e-01,  9.3852e-02,\n",
       "            -4.9200e-02],\n",
       "           [-1.6202e-01, -2.8411e-01, -3.3291e-02,  1.5584e-01, -1.5318e-01,\n",
       "            -2.2087e-01,  1.0154e-01,  5.9632e-02,  2.4885e-01, -2.4487e-01,\n",
       "            -7.3266e-02],\n",
       "           [ 2.0714e-01,  2.0975e-01,  1.4103e-01,  1.0621e-01,  2.6340e-01,\n",
       "             1.2819e-01,  2.9925e-01,  1.3443e-01,  7.9033e-02,  2.7140e-01,\n",
       "            -3.2584e-02],\n",
       "           [-2.6833e-01, -1.5230e-01, -1.3197e-01, -1.1239e-01, -6.0320e-02,\n",
       "            -1.3186e-01, -2.7904e-01,  1.5589e-01, -1.1990e-01, -4.9897e-02,\n",
       "             4.9900e-02],\n",
       "           [-2.7693e-01, -1.1911e-02,  9.6844e-02, -2.2023e-01,  1.3709e-01,\n",
       "             2.6073e-01, -2.1776e-01, -1.4513e-01, -1.0610e-01,  2.5537e-02,\n",
       "            -1.8800e-01]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.2733,  0.1662, -0.1502,  0.3061, -0.1376,  0.2416,  0.0305, -0.2958,\n",
       "             0.1942,  0.0656],\n",
       "           [ 0.2670,  0.1505,  0.0720,  0.0478, -0.0389, -0.0519, -0.1231, -0.2520,\n",
       "             0.0297,  0.0363],\n",
       "           [ 0.0066,  0.2466, -0.0565, -0.0347, -0.0899,  0.2116, -0.2642, -0.2643,\n",
       "             0.0226, -0.2903],\n",
       "           [-0.2118, -0.0772, -0.2617,  0.0153, -0.2373,  0.0534,  0.1938,  0.1497,\n",
       "            -0.0022, -0.2074],\n",
       "           [-0.0887, -0.0510,  0.2321,  0.0844,  0.0514, -0.1923,  0.0517,  0.0412,\n",
       "            -0.0166, -0.2689],\n",
       "           [-0.0458,  0.2069,  0.2666,  0.1868,  0.1416, -0.2566,  0.1441, -0.0188,\n",
       "             0.2446, -0.1163],\n",
       "           [ 0.2824, -0.0032, -0.2067,  0.1668, -0.0234,  0.0703, -0.2997,  0.0139,\n",
       "             0.0069,  0.0111],\n",
       "           [-0.1665, -0.0750, -0.1879, -0.0837, -0.1830, -0.0148, -0.1063,  0.2398,\n",
       "            -0.2138, -0.0488],\n",
       "           [-0.1513,  0.1860,  0.1928,  0.2239,  0.0513, -0.1644, -0.2232, -0.1011,\n",
       "             0.0357, -0.1703],\n",
       "           [ 0.2816, -0.0355, -0.3031,  0.1016,  0.1368, -0.1851,  0.0755,  0.2340,\n",
       "            -0.2177,  0.2820]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0101, -0.2752,  0.2844, -0.1030, -0.0642, -0.0279,  0.3158, -0.2602,\n",
       "             0.2845, -0.1746]], requires_grad=True)],\n",
       "  'weight_decay': 1.0},\n",
       " {'params': [Parameter containing:\n",
       "   tensor([1., 1.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0129,  0.0001,  0.0092, -0.0013, -0.0095],\n",
       "           [-0.0080, -0.0057,  0.0008,  0.0106,  0.0108],\n",
       "           [-0.0148, -0.0023,  0.0063, -0.0119, -0.0132],\n",
       "           [ 0.0113,  0.0097,  0.0015,  0.0108, -0.0065],\n",
       "           [ 0.0023, -0.0009, -0.0001, -0.0100, -0.0020]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0023,  0.0069,  0.0099, -0.0182],\n",
       "           [ 0.0041,  0.0039, -0.0077,  0.0029],\n",
       "           [-0.0041,  0.0064, -0.0015,  0.0101],\n",
       "           [-0.0130, -0.0070,  0.0072, -0.0112]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0296,  0.1635, -0.0498,  0.1368, -0.0737, -0.0530,  0.2239, -0.2125,\n",
       "           -0.2742, -0.2882], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.1122, -0.1679, -0.2581,  0.1717, -0.0730,  0.2728, -0.2337, -0.2124,\n",
       "           -0.1315, -0.1592], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.1745], requires_grad=True)],\n",
       "  'weight_decay': 0.0}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_param_groups(tabnn, 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learner V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LearnerV0:\n",
    "    \n",
    "    def __init__(self, model, dataloaders, opt_func, loss_func, metrics=None, use_gpu=True, savepath='./models'):\n",
    "        \n",
    "        self.device = 'cuda' if (torch.cuda.is_available() and use_gpu) else 'cpu'\n",
    "        self.model = model.to(self.device)\n",
    "        \n",
    "        self.train_dl = dataloaders[0]\n",
    "        self.valid_dl = dataloaders[1]\n",
    "        self.test_dl = dataloaders[2] if len(dataloaders)>2 else None\n",
    "        \n",
    "        self.opt_func = opt_func\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.train_losses = AverageMeter(store_vals=True)\n",
    "        self.valid_losses = AverageMeter(store_avgs=True)\n",
    "        self.accs = AverageMeter()\n",
    "#         self.optimizer = opt_func([p for p in self.model.parameters() if p.requires_grad])\n",
    "        \n",
    "        self.savepath = Path(savepath)\n",
    "        if not self.savepath.exists():\n",
    "            self.savepath.mkdir()\n",
    "        self.training = True\n",
    "        self.epoch = -1\n",
    "        \n",
    "    def fit(self, epochs, lr=1e-2):\n",
    "        \n",
    "        self.optimizer = self.opt_func([p for p in self.model.parameters() if p.requires_grad], lr)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            self.epoch += 1\n",
    "            train_loss = self.train()\n",
    "            self.train_losses.reset()\n",
    "            \n",
    "            valid_loss, acc = self.validate()\n",
    "            self.valid_losses.reset()\n",
    "            self.accs.reset()\n",
    "            \n",
    "#             print('Train loss = {:f}; valid loss = {:f}; {} = {:f}'.\\\n",
    "#                   format(train_loss, valid_loss, self.metrics.__name__, acc))\n",
    "            self.save_model()\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        self.model.train()\n",
    "        pbar = tqdm(self.train_dl)\n",
    "        for x_cat, x_cont, y in pbar:\n",
    "            x_cat = x_cat.to(self.device, dtype=torch.long)\n",
    "            x_cont = x_cont.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pred = self.model(x_cat, x_cont)\n",
    "            loss = self.loss_func(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.train_losses.update(loss.item())\n",
    "            pbar.set_description(f'epoch {self.epoch+1}: train loss {self.train_losses.avg:.4f}')\n",
    "        return self.train_losses.avg\n",
    "    \n",
    "    def validate(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        pbar = tqdm(self.valid_dl)\n",
    "        for x_cat, x_cont, y in pbar:\n",
    "            x_cat = x_cat.to(self.device, dtype=torch.long)\n",
    "            x_cont = x_cont.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(x_cat, x_cont)\n",
    "                loss = self.loss_func(pred, y)\n",
    "\n",
    "            self.valid_losses.update(loss.item())\n",
    "            self.accs.update(accuracy_binary(pred, y).item())\n",
    "            pbar.set_description(f'epoch {self.epoch+1}: valid loss {self.valid_losses.avg:.4f}, accuracy {self.accs.avg :.4f}')\n",
    "        \n",
    "        return self.valid_losses.avg, self.accs.avg\n",
    "    \n",
    "    def save_model(self, fn='ckpt_', path=None):\n",
    "        if not path: path = self.savepath\n",
    "        fn += str(self.epoch) + '.pt'\n",
    "        torch.save(self.model.state_dict(), path/fn)\n",
    "    \n",
    "    def load_model(self, fn, path=None):\n",
    "        if not path: path = self.savepath\n",
    "        self.model.load_state_dict(torch.load(path/fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learner V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LearnerV1:\n",
    "    \n",
    "    def __init__(self, model, dataloaders, opt_func, loss_func, metrics=None, use_gpu=True, savepath='./models'):\n",
    "        \n",
    "        self.device = 'cuda' if (torch.cuda.is_available() and use_gpu) else 'cpu'\n",
    "        self.model = model.to(self.device)\n",
    "        \n",
    "        self.train_dl = dataloaders[0]\n",
    "        self.valid_dl = dataloaders[1]\n",
    "        self.test_dl = dataloaders[2] if len(dataloaders)>2 else None\n",
    "        \n",
    "        self.opt_func = opt_func\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.train_losses = AverageMeter(store_vals=True)\n",
    "        self.valid_losses = AverageMeter(store_avgs=True)\n",
    "        self.accs = AverageMeter()\n",
    "#         self.optimizer = opt_func([p for p in self.model.parameters() if p.requires_grad])\n",
    "        \n",
    "        self.savepath = Path(savepath)\n",
    "        if not self.savepath.exists():\n",
    "            self.savepath.mkdir()\n",
    "        self.training = True\n",
    "        self.epoch = -1\n",
    "        \n",
    "    def fit(self, epochs, lr=1e-2, wd=0.):\n",
    "        \n",
    "        if wd:\n",
    "            params = wd_param_groups(self.model, wd)\n",
    "        else:\n",
    "            params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        self.optimizer = self.opt_func(params, lr)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            self.epoch += 1\n",
    "            train_loss = self.train()\n",
    "            self.train_losses.reset()\n",
    "            \n",
    "            valid_loss, acc = self.validate()\n",
    "            self.valid_losses.reset()\n",
    "            self.accs.reset()\n",
    "            \n",
    "            self.save_model()\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        self.model.train()\n",
    "        pbar = tqdm(self.train_dl)\n",
    "        for x_cat, x_cont, y in pbar:\n",
    "            x_cat = x_cat.to(self.device, dtype=torch.long)\n",
    "            x_cont = x_cont.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pred = self.model(x_cat, x_cont)\n",
    "            loss = self.loss_func(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.train_losses.update(loss.item())\n",
    "            pbar.set_description(f'epoch {self.epoch+1}: train loss {self.train_losses.avg:.4f}')\n",
    "        return self.train_losses.avg\n",
    "    \n",
    "    def validate(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        pbar = tqdm(self.valid_dl)\n",
    "        for x_cat, x_cont, y in pbar:\n",
    "            x_cat = x_cat.to(self.device, dtype=torch.long)\n",
    "            x_cont = x_cont.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(x_cat, x_cont)\n",
    "                loss = self.loss_func(pred, y)\n",
    "\n",
    "            self.valid_losses.update(loss.item())\n",
    "            self.accs.update(accuracy_binary(pred, y).item())\n",
    "            pbar.set_description(f'epoch {self.epoch+1}: valid loss {self.valid_losses.avg:.4f}, accuracy {self.accs.avg :.4f}')\n",
    "        \n",
    "        return self.valid_losses.avg, self.accs.avg\n",
    "    \n",
    "    def save_model(self, fn='ckpt_', path=None):\n",
    "        if not path: path = self.savepath\n",
    "        fn += str(self.epoch) + '.pt'\n",
    "        torch.save(self.model.state_dict(), path/fn)\n",
    "    \n",
    "    def load_model(self, fn, path=None):\n",
    "        if not path: path = self.savepath\n",
    "        self.model.load_state_dict(torch.load(path/fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00a_test_utils.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
