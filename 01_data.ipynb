{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import gc\n",
    "import typing\n",
    "from pathlib import Path\n",
    "from math import isclose\n",
    "from typing import Sequence, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from nn4tab.test_utils import fake_data, test_normalized, test_categorical, test_nans, test_df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularProc():\n",
    "    _order = 1\n",
    "    isset = False\n",
    "    def setup(self): pass\n",
    "    def checkup(self):\n",
    "        pass\n",
    "    def encode(self, x):\n",
    "        raise NotImplementedError\n",
    "    def decode(self, x): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _readargs(**kwargs):\n",
    "    ds = kwargs.get('ds', None)\n",
    "    if ds is not None:\n",
    "        return vars(ds)\n",
    "    df = kwargs.get('df', None)\n",
    "    if df is None:\n",
    "        raise RuntimeError(\"Either dataset or dataframe should be in arguments\")\n",
    "    cont_names = kwargs.get('cont_names', None)\n",
    "    cat_names = kwargs.get('cat_names', None)\n",
    "    return {'data':df,\n",
    "            'cont_names':cont_names,\n",
    "            'cat_names':cat_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(df):\n",
    "    print('*'*15)\n",
    "    for col in cont_names:\n",
    "        print(f'{col}: mean= {df[col].mean():.4f}, std = {df[col].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Normalize(TabularProc):\n",
    "    \"\"\"\n",
    "    Normalizes continuous features to zero mean and unit variance.\n",
    "    \"\"\"\n",
    "    def setup(self, data:Union[Dataset, pd.DataFrame], cont_names:Sequence=[]):\n",
    "        \"\"\"Store mean and std for columns in cont_names\"\"\"\n",
    "        self.checkup()\n",
    "        data, cont_names = self._argcheck(data, cont_names)\n",
    "        self.mean = {col: data[col].mean() for col in cont_names}\n",
    "        self.std = {col: data[col].std() for col in cont_names}\n",
    "        self.isset = True\n",
    "    \n",
    "    def _argcheck(self, data, cont_names):\n",
    "        if isinstance(data, Dataset):\n",
    "            if not cont_names: cont_names = data.cont_names\n",
    "            data = data.data\n",
    "        else:\n",
    "            if not cont_names:\n",
    "                raise Warning(\"Given no columns to process\")\n",
    "        return data, cont_names\n",
    "        \n",
    "    def encode_one(self, df:pd.DataFrame, col:str):\n",
    "        return (df[col] - self.mean[col])/self.std[col]\n",
    "\n",
    "    def encode(self, data:Union[Dataset, pd.DataFrame], cont_names:Sequence=[]):\n",
    "        data, cont_names = self._argcheck(data, cont_names)\n",
    "        if not self.isset: self.setup(data, cont_names)\n",
    "        for col in cont_names:\n",
    "            data[col] = self.encode_one(data, col)\n",
    "    \n",
    "    def decode_one(self, df:pd.DataFrame, col:str):\n",
    "        return df[col]*self.std[col] + self.mean[col]\n",
    "    \n",
    "    def decode(self, data:Union[Dataset, pd.DataFrame], cont_names:Sequence=[]):\n",
    "        data, cont_names = self._argcheck(data, cont_names)\n",
    "        for col in cont_names:\n",
    "            data[col] = self.decode_one(data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  1000 non-null   float32\n",
      " 1   cont_1  1000 non-null   float32\n",
      " 2   cont_2  1000 non-null   float32\n",
      " 3   cont_3  1000 non-null   float32\n",
      " 4   cont_4  1000 non-null   float32\n",
      " 5   cat_0   1000 non-null   object \n",
      " 6   cat_1   1000 non-null   object \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), object(2)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False)\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "cont_0: mean= -1.6134, std = 2.5976\n",
      "cont_1: mean= 4.8120, std = 2.7086\n",
      "cont_2: mean= -1.8440, std = 2.4517\n",
      "cont_3: mean= 2.8474, std = 1.4774\n",
      "cont_4: mean= 3.6936, std = 2.9721\n",
      "***************\n",
      "cont_0: mean= 0.0000, std = 1.0000\n",
      "cont_1: mean= 0.0000, std = 1.0000\n",
      "cont_2: mean= -0.0000, std = 1.0000\n",
      "cont_3: mean= 0.0000, std = 1.0000\n",
      "cont_4: mean= -0.0000, std = 1.0000\n"
     ]
    }
   ],
   "source": [
    "norm = Normalize()\n",
    "norm.setup(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "norm.encode(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "test_normalized(test_df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "cont_0: mean= -1.6134, std = 2.5976\n",
      "cont_1: mean= 4.8120, std = 2.7086\n",
      "cont_2: mean= -1.8440, std = 2.4517\n",
      "cont_3: mean= 2.8474, std = 1.4774\n",
      "cont_4: mean= 3.6936, std = 2.9721\n"
     ]
    }
   ],
   "source": [
    "norm.decode(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "for x in (test_df[cont_names] - df[cont_names]).abs().sum():\n",
    "    assert x < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_names, cat_names = fake_data()\n",
    "test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "cont_0: mean= 0.0436, std = 1.0146\n",
      "cont_1: mean= -0.0250, std = 0.9849\n",
      "cont_2: mean= -0.0127, std = 0.9841\n",
      "cont_3: mean= -0.0235, std = 1.0335\n",
      "cont_4: mean= -0.0028, std = 1.0229\n",
      "***************\n",
      "cont_0: mean= 0.0000, std = 1.0000\n",
      "cont_1: mean= 0.0000, std = 1.0000\n",
      "cont_2: mean= -0.0000, std = 1.0000\n",
      "cont_3: mean= -0.0000, std = 1.0000\n",
      "cont_4: mean= 0.0000, std = 1.0000\n"
     ]
    }
   ],
   "source": [
    "norm = Normalize()\n",
    "norm.setup(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "norm.encode(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "test_normalized(test_df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "cont_0: mean= 0.0436, std = 1.0146\n",
      "cont_1: mean= -0.0250, std = 0.9849\n",
      "cont_2: mean= -0.0127, std = 0.9841\n",
      "cont_3: mean= -0.0235, std = 1.0335\n",
      "cont_4: mean= -0.0028, std = 1.0229\n"
     ]
    }
   ],
   "source": [
    "norm.decode(test_df, cont_names)\n",
    "\n",
    "print_stat(test_df)\n",
    "\n",
    "for x in (test_df[cont_names] - df[cont_names]).abs().sum():\n",
    "    assert x < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FillMissing proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FillMissing(TabularProc):\n",
    "    \"\"\"Fills missing values in continuous columns\"\"\"\n",
    "    def __init__(self, add_bool=True, method='mean'):\n",
    "        self.add_bool = add_bool\n",
    "        self.method = method\n",
    "        \n",
    "    def setup(self, data:Union[Dataset, pd.DataFrame], cont_names:Sequence=[], cat_names:Sequence=[]):\n",
    "        self.checkup()\n",
    "        data, cont_names = self._argcheck(data, cont_names)\n",
    "        if self.method == 'mean':\n",
    "            self.values = {col:data[col].mean() for col in cont_names}\n",
    "        self.cont_names = cont_names\n",
    "        self.cat_names = cat_names\n",
    "        self.isset = True\n",
    "        \n",
    "    def _argcheck(self, data, cont_names):\n",
    "        if isinstance(data, Dataset):\n",
    "            if not cont_names: cont_names = data.cont_names\n",
    "            data = data.data\n",
    "        else:\n",
    "            if not cont_names:\n",
    "                raise Warning(\"Given no columns to process\")\n",
    "        return data, cont_names\n",
    "    \n",
    "    def encode(self, data:Union[Dataset, pd.DataFrame], cont_names:Sequence=[]):\n",
    "        data, cont_names = self._argcheck(data, cont_names)\n",
    "        if not self.isset: self.setup(data, cont_names)\n",
    "        for col in cont_names:\n",
    "            if data[col].notna().all():\n",
    "                continue\n",
    "            if self.add_bool:\n",
    "                data[f'{col}_na'] = data[col].isna().astype(np.int8)\n",
    "            data[col].fillna(value=self.values[col], inplace=True)\n",
    "            \n",
    "    def decode(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   891 non-null    float64\n",
      " 6   cat_1   902 non-null    float64\n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), float64(2)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(nans=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillproc = FillMissing()\n",
    "fillproc.setup(test_df, cont_names, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillproc.encode(df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   cont_0     1000 non-null   float32\n",
      " 1   cont_1     1000 non-null   float32\n",
      " 2   cont_2     1000 non-null   float32\n",
      " 3   cont_3     1000 non-null   float32\n",
      " 4   cont_4     1000 non-null   float32\n",
      " 5   cat_0      891 non-null    float64\n",
      " 6   cat_1      902 non-null    float64\n",
      " 7   targ       1000 non-null   float32\n",
      " 8   cont_0_na  1000 non-null   int8   \n",
      " 9   cont_1_na  1000 non-null   int8   \n",
      " 10  cont_2_na  1000 non-null   int8   \n",
      " 11  cont_3_na  1000 non-null   int8   \n",
      " 12  cont_4_na  1000 non-null   int8   \n",
      "dtypes: float32(6), float64(2), int8(5)\n",
      "memory usage: 44.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currentlly NaN values in categorical columns are handled by Categorify proc\n",
    "test_nans(df, cont_names, cat_names=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorify proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _catlist(s:pd.Series):\n",
    "    c = set(s)\n",
    "    c.discard('#na')\n",
    "    return ['#na'] + list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorify(TabularProc):\n",
    "    \"\"\"Numericalizes categorical columns.\"\"\"\n",
    "    def setup(self, data:Union[Dataset, pd.DataFrame], cat_names:Sequence=[]):\n",
    "        self.checkup()\n",
    "        data, cat_names = self._argcheck(data, cat_names)\n",
    "        self.cat = {col: _catlist(data[col].dropna()) for col in cat_names}\n",
    "        self.i2c = {c: i for i, c in enumerate(self.cat)}\n",
    "        self.isset = True\n",
    "\n",
    "    def _argcheck(self, data, cat_names):\n",
    "        if isinstance(data, Dataset):\n",
    "            if not cat_names: cat_names = data.cat_names\n",
    "            data = data.data\n",
    "        else:\n",
    "            if not cat_names:\n",
    "                raise Warning(\"Given no columns to process\")\n",
    "        return data, cat_names\n",
    "    \n",
    "    def encode_one(self, df:pd.DataFrame, col:str):\n",
    "        return pd.Series(pd.Categorical(df[col].fillna('#na'), categories=self.cat[col])).cat.codes\n",
    "    \n",
    "    def encode(self, data:Union[Dataset, pd.DataFrame], cat_names:Sequence=[]):\n",
    "        data, cat_names = self._argcheck(data, cat_names)\n",
    "        if not self.isset: self.setup(data, cat_names)\n",
    "        for col in cat_names:\n",
    "            data[col] = self.encode_one(data, col)\n",
    "    \n",
    "    def decode_one(self, df:pd.DataFrame, col:str):\n",
    "        return pd.Series(pd.Categorical.from_codes(df[col], categories=self.cat[col]))\n",
    "    \n",
    "    def decode(self, data:Union[Dataset, pd.DataFrame], cat_names:Sequence=[]):\n",
    "        data, cat_names = self._argcheck(data, cat_names)\n",
    "        for col in cat_names:\n",
    "            data[col] = self.decode_one(data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   891 non-null    object \n",
      " 6   cat_1   901 non-null    object \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), object(2)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False, nans=True)\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat_0': ['#na', 'C', 'A', 'B'], 'cat_1': ['#na', 'C', 'B', 'A']}\n"
     ]
    }
   ],
   "source": [
    "cproc = Categorify()\n",
    "cproc.setup(test_df, cat_names)\n",
    "\n",
    "assert cproc.isset\n",
    "print(cproc.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   1000 non-null   int8   \n",
      " 6   cat_1   1000 non-null   int8   \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), int8(2)\n",
      "memory usage: 25.5 KB\n"
     ]
    }
   ],
   "source": [
    "cproc.encode(test_df, cat_names)\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_names:\n",
    "    assert sum(test_df.loc[df[col].isna(), col]) == 0, f'Error when handling nans in {col}'\n",
    "    assert np.issubdtype(test_df[col].dtype, np.integer), f'{col} dtype is not int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cproc.decode(test_df, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_names:\n",
    "    assert (df.loc[df[col].notna(), col] == test_df.loc[df[col].notna(), col]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  1000 non-null   float32\n",
      " 1   cont_1  1000 non-null   float32\n",
      " 2   cont_2  1000 non-null   float32\n",
      " 3   cont_3  1000 non-null   float32\n",
      " 4   cont_4  1000 non-null   float32\n",
      " 5   cat_0   1000 non-null   int64  \n",
      " 6   cat_1   1000 non-null   int64  \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), int64(2)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data()\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat_0': ['#na', 0, 1, 2], 'cat_1': ['#na', 0, 1, 2]}\n"
     ]
    }
   ],
   "source": [
    "cproc = Categorify()\n",
    "cproc.setup(test_df, cat_names)\n",
    "\n",
    "assert cproc.isset\n",
    "print(cproc.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  1000 non-null   float32\n",
      " 1   cont_1  1000 non-null   float32\n",
      " 2   cont_2  1000 non-null   float32\n",
      " 3   cont_3  1000 non-null   float32\n",
      " 4   cont_4  1000 non-null   float32\n",
      " 5   cat_0   1000 non-null   int8   \n",
      " 6   cat_1   1000 non-null   int8   \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), int8(2)\n",
      "memory usage: 25.5 KB\n"
     ]
    }
   ],
   "source": [
    "cproc.encode(test_df, cat_names)\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cproc.decode(test_df, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_names:\n",
    "    assert (df.loc[df[col].notna(), col] == test_df.loc[df[col].notna(), col]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ProcPipeline:\n",
    "    \"\"\"\n",
    "    Combines data processors into pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, procs:Sequence[TabularProc]):\n",
    "        self._procs = procs\n",
    "        self.reset()\n",
    "        \n",
    "    def setup(self, data):\n",
    "        # todo\n",
    "        return\n",
    "        if not self.isset:\n",
    "            for proc in self.procs:\n",
    "                proc.setup(data)\n",
    "        self.isset = True\n",
    "        \n",
    "    def encode(self, data):\n",
    "        for proc in self.procs:\n",
    "            proc.encode(data)\n",
    "            \n",
    "    def decode(self, data):\n",
    "        for proc in self.procs:\n",
    "            proc.decode(data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.procs[i]\n",
    "    \n",
    "    def reset(self):\n",
    "        procs = [p() for p in self._procs]\n",
    "        self.procs = sorted(procs, key=lambda p: p._order)\n",
    "        self.isset = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cont_cat_split(df, dep_var=None, max_card=np.inf, ignore=[]):\n",
    "    \"\"\"\n",
    "    Sugests a split of columns of the dataframe to continuous and categorical ommiting dep_var and \n",
    "    ignore. Split is done based on column datatype: float columns and int with cardinality > max_card \n",
    "    are treated as continuous, all other - categorical.\n",
    "    \"\"\"\n",
    "    cont, cat = [], []\n",
    "    for col in df.columns:\n",
    "        if (col == dep_var) or (col in dep_var) or (col in ignore): continue\n",
    "        if np.issubdtype(df[col].dtype, np.floating) or (len(df[col].unique()) > max_card and np.issubdtype(df[col].dtype, np.integer)):\n",
    "            cont.append(col)\n",
    "        else: #?? any condition np.issubdtype(df[col].dtype, np.integer) \n",
    "            cat.append(col)\n",
    "    return cont, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for continious data.\n",
    "    Produces tuple containing numpy arrays:\n",
    "        x_cat, x_cont, y\n",
    "    \"\"\"\n",
    "    def __init__(self, df:pd.DataFrame, cont_names:Sequence, cat_names:Sequence, dep_var:Sequence,\n",
    "                 procs=[], copy=True):\n",
    "        self.data = df.copy() if copy else df\n",
    "        self.cat_names = cat_names\n",
    "        self.cont_names = cont_names\n",
    "        self.dep_var = dep_var\n",
    "        self.procs = procs if isinstance(procs, ProcPipeline) else ProcPipeline(procs)\n",
    "        self.procs.encode(self)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[self.cat_names].iloc[idx].to_numpy(dtype=np.long), \n",
    "                self.data[self.cont_names].iloc[idx].to_numpy(dtype=np.float32), \n",
    "                self.data[self.dep_var].iloc[idx].to_numpy(dtype=np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _decode(self):\n",
    "        self.procs.decode(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   891 non-null    object \n",
      " 6   cat_1   901 non-null    object \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), object(2)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False, nans=True)\n",
    "dep_var = ['targ']\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize, FillMissing, Categorify]\n",
    "pipe = ProcPipeline(procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont_0</th>\n",
       "      <th>cont_1</th>\n",
       "      <th>cont_2</th>\n",
       "      <th>cont_3</th>\n",
       "      <th>cont_4</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.237776</td>\n",
       "      <td>4.726856</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>5.035037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.165130</td>\n",
       "      <td>4.755350</td>\n",
       "      <td>1.774184</td>\n",
       "      <td>1.690559</td>\n",
       "      <td>2.819697</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.801118</td>\n",
       "      <td>5.582966</td>\n",
       "      <td>-5.896749</td>\n",
       "      <td>3.399724</td>\n",
       "      <td>3.353442</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.345072</td>\n",
       "      <td>4.445452</td>\n",
       "      <td>-1.267434</td>\n",
       "      <td>0.292013</td>\n",
       "      <td>8.225743</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.939306</td>\n",
       "      <td>-1.294417</td>\n",
       "      <td>-2.017090</td>\n",
       "      <td>4.966501</td>\n",
       "      <td>2.186796</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cont_0    cont_1    cont_2    cont_3    cont_4 cat_0 cat_1  targ\n",
       "0  0.237776  4.726856  0.328851  5.035037       NaN   NaN     C   1.0\n",
       "1 -0.165130  4.755350  1.774184  1.690559  2.819697     A     A   1.0\n",
       "2 -0.801118  5.582966 -5.896749  3.399724  3.353442     C   NaN   0.0\n",
       "3 -2.345072  4.445452 -1.267434  0.292013  8.225743     A     A   0.0\n",
       "4 -3.939306 -1.294417 -2.017090  4.966501  2.186796     C     B   0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TabularDataset(df, cont_names, cat_names, dep_var)\n",
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont_0</th>\n",
       "      <th>cont_1</th>\n",
       "      <th>cont_2</th>\n",
       "      <th>cont_3</th>\n",
       "      <th>cont_4</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>targ</th>\n",
       "      <th>cont_0_na</th>\n",
       "      <th>cont_1_na</th>\n",
       "      <th>cont_2_na</th>\n",
       "      <th>cont_3_na</th>\n",
       "      <th>cont_4_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715700</td>\n",
       "      <td>-0.030405</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>1.466304</td>\n",
       "      <td>2.773549e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.559190</td>\n",
       "      <td>-0.019687</td>\n",
       "      <td>1.466657</td>\n",
       "      <td>-0.767848</td>\n",
       "      <td>-2.901395e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.312139</td>\n",
       "      <td>0.291596</td>\n",
       "      <td>-1.611295</td>\n",
       "      <td>0.373895</td>\n",
       "      <td>-1.118203e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287613</td>\n",
       "      <td>-0.136246</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>-1.702093</td>\n",
       "      <td>1.515969e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.906897</td>\n",
       "      <td>-2.295129</td>\n",
       "      <td>-0.054587</td>\n",
       "      <td>1.420521</td>\n",
       "      <td>-5.015854e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cont_0    cont_1    cont_2    cont_3        cont_4  cat_0  cat_1  targ  \\\n",
       "0  0.715700 -0.030405  0.886719  1.466304  2.773549e-08      0      1   1.0   \n",
       "1  0.559190 -0.019687  1.466657 -0.767848 -2.901395e-01      2      3   1.0   \n",
       "2  0.312139  0.291596 -1.611295  0.373895 -1.118203e-01      1      0   0.0   \n",
       "3 -0.287613 -0.136246  0.246211 -1.702093  1.515969e+00      2      3   0.0   \n",
       "4 -0.906897 -2.295129 -0.054587  1.420521 -5.015854e-01      1      2   0.0   \n",
       "\n",
       "   cont_0_na  cont_1_na  cont_2_na  cont_3_na  cont_4_na  \n",
       "0          0          0          0          0          1  \n",
       "1          0          0          0          0          0  \n",
       "2          0          0          0          0          0  \n",
       "3          0          0          0          0          0  \n",
       "4          0          0          0          0          0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.encode(ds)\n",
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, cont_names, cat_names, dep_var=dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False)\n",
    "dep_var = ['targ']\n",
    "procs = [Normalize, FillMissing, Categorify]\n",
    "pipe = ProcPipeline(procs)\n",
    "ds = TabularDataset(df, cont_names, cat_names, dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.encode(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, cont_names, cat_names, dep_var=dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.decode(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_names, cat_names = fake_data()\n",
    "dep_var = ['targ']\n",
    "procs = [Normalize, FillMissing, Categorify]\n",
    "pipe = ProcPipeline(procs)\n",
    "ds = TabularDataset(df, cont_names, cat_names, dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1]),\n",
       " array([-1.7382663 , -1.3366427 , -1.3611068 , -0.35161713, -2.3125815 ],\n",
       "       dtype=float32),\n",
       " array([0.], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, ds.cont_names, ds.cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False)\n",
    "dep_var = ['targ']\n",
    "procs = [Normalize, FillMissing, Categorify]\n",
    "pipe = ProcPipeline(procs)\n",
    "ds = TabularDataset(df, cont_names, cat_names, dep_var, procs=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, ds.cont_names, ds.cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont_0</th>\n",
       "      <th>cont_1</th>\n",
       "      <th>cont_2</th>\n",
       "      <th>cont_3</th>\n",
       "      <th>cont_4</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.712654</td>\n",
       "      <td>-0.031417</td>\n",
       "      <td>0.886253</td>\n",
       "      <td>1.480729</td>\n",
       "      <td>-0.639405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557549</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>1.475774</td>\n",
       "      <td>-0.782973</td>\n",
       "      <td>-0.294020</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.312715</td>\n",
       "      <td>0.284651</td>\n",
       "      <td>-1.653041</td>\n",
       "      <td>0.373872</td>\n",
       "      <td>-0.114436</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.281655</td>\n",
       "      <td>-0.135309</td>\n",
       "      <td>0.235161</td>\n",
       "      <td>-1.729575</td>\n",
       "      <td>1.524899</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.895380</td>\n",
       "      <td>-2.254419</td>\n",
       "      <td>-0.070608</td>\n",
       "      <td>1.434341</td>\n",
       "      <td>-0.506966</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cont_0    cont_1    cont_2    cont_3    cont_4  cat_0  cat_1  targ\n",
       "0  0.712654 -0.031417  0.886253  1.480729 -0.639405      1      1   1.0\n",
       "1  0.557549 -0.020897  1.475774 -0.782973 -0.294020      3      3   1.0\n",
       "2  0.312715  0.284651 -1.653041  0.373872 -0.114436      1      2   0.0\n",
       "3 -0.281655 -0.135309  0.235161 -1.729575  1.524899      3      3   0.0\n",
       "4 -0.895380 -2.254419 -0.070608  1.434341 -0.506966      1      2   0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False, nans=True)\n",
    "dep_var = ['targ']\n",
    "procs = [Normalize, FillMissing, Categorify]\n",
    "pipe = ProcPipeline(procs)\n",
    "ds = TabularDataset(df, cont_names, cat_names, dep_var, procs=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]),\n",
       " array([ 7.1570003e-01, -3.0404553e-02,  8.8671887e-01,  1.4663039e+00,\n",
       "         2.7735494e-08], dtype=float32),\n",
       " array([1.], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, ds.cont_names, ds.cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   cont_0     1000 non-null   float32\n",
      " 1   cont_1     1000 non-null   float32\n",
      " 2   cont_2     1000 non-null   float32\n",
      " 3   cont_3     1000 non-null   float32\n",
      " 4   cont_4     1000 non-null   float32\n",
      " 5   cat_0      1000 non-null   int8   \n",
      " 6   cat_1      1000 non-null   int8   \n",
      " 7   targ       1000 non-null   float32\n",
      " 8   cont_0_na  1000 non-null   int8   \n",
      " 9   cont_1_na  1000 non-null   int8   \n",
      " 10  cont_2_na  1000 non-null   int8   \n",
      " 11  cont_3_na  1000 non-null   int8   \n",
      " 12  cont_4_na  1000 non-null   int8   \n",
      "dtypes: float32(6), int8(7)\n",
      "memory usage: 30.4 KB\n"
     ]
    }
   ],
   "source": [
    "ds.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test adult ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('./datasets/adult.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = (df['salary'].apply(lambda x: x=='>=50k')).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['age',\n",
       "  'fnlwgt',\n",
       "  'education-num',\n",
       "  'capital-gain',\n",
       "  'capital-loss',\n",
       "  'hours-per-week'],\n",
       " ['workclass',\n",
       "  'education',\n",
       "  'marital-status',\n",
       "  'occupation',\n",
       "  'relationship',\n",
       "  'race',\n",
       "  'sex',\n",
       "  'native-country'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_var = ['salary']\n",
    "cont_names, cat_names = cont_cat_split(df, dep_var, max_card=10)\n",
    "cont_names, cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize, FillMissing, Categorify]\n",
    "ds = TabularDataset(df, cont_names, cat_names, dep_var, procs=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(ds.data, ds.cont_names, ds.cat_names, ds.dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  6,  6,  0,  1,  1,  2, 19]),\n",
       " array([ 0.76378465, -0.8380709 ,  0.74628264, -0.14591825,  4.5034127 ,\n",
       "        -0.0354289 ], dtype=float32),\n",
       " array([1.], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "class Datasets:\n",
    "    \n",
    "    def __init__(self, *dfs, dsclass:Dataset=TabularDataset, \n",
    "                 cat_names:Sequence, cont_names:Sequence, dep_var:Sequence, procs=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dsets(df:pd.DataFrame, cont_names:Sequence, cat_names:Sequence, dep_var:Sequence,\n",
    "              procs=[], splits=None, stratify=True):\n",
    "    if splits:\n",
    "        train_df, valid_df = df[splits[0]].copy(), df[splits[1]].copy()\n",
    "    else:\n",
    "        s = df[dep_var[0]] if stratify else None\n",
    "        train_df, valid_df = train_test_split(df, test_size=0.2, stratify=s)\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    valid_df.reset_index(drop=True, inplace=True)\n",
    "    train_ds = TabularDataset(train_df, cont_names, cat_names, dep_var, procs=procs)\n",
    "    valid_ds = TabularDataset(valid_df, cont_names, cat_names, dep_var, procs=train_ds.procs)\n",
    "    return (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize, FillMissing, Categorify]\n",
    "train_ds, valid_ds = get_dsets(df, cont_names, cat_names, dep_var, procs=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(train_ds.data, train_ds.cont_names, train_ds.cat_names, train_ds.dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_processed(valid_ds.data, valid_ds.cont_names, valid_ds.cat_names, valid_ds.dep_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              -4.756637e-17\n",
       "fnlwgt            1.181999e-16\n",
       "education-num    -1.673984e-16\n",
       "capital-gain      3.549896e-16\n",
       "capital-loss     -1.892255e-16\n",
       "hours-per-week   -4.441148e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.data[train_ds.cont_names].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0.000039\n",
       "fnlwgt            0.014496\n",
       "education-num    -0.000357\n",
       "capital-gain      0.016158\n",
       "capital-loss     -0.021486\n",
       "hours-per-week    0.008863\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds.data[valid_ds.cont_names].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dl(ds, bs=512, train=True, drop_last=True):\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=train, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00a_test_utils.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
