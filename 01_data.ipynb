{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import gc\n",
    "import typing\n",
    "from math import isclose\n",
    "from typing import Sequence, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nn4tab.test_utils import fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularProc():\n",
    "    _order = 1\n",
    "    isset = False\n",
    "    def setup(self): pass\n",
    "    def checkup(self):\n",
    "        pass\n",
    "    def encode(self, x):\n",
    "        raise NotImplementedError\n",
    "    def decode(self, x): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  1000 non-null   float32\n",
      " 1   cont_1  1000 non-null   float32\n",
      " 2   cont_2  1000 non-null   float32\n",
      " 3   cont_3  1000 non-null   float32\n",
      " 4   cont_4  1000 non-null   float32\n",
      " 5   cat_0   1000 non-null   object \n",
      " 6   cat_1   1000 non-null   object \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), object(2)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False)\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "class ProcPipeline:\n",
    "    def __init__(self, procs:Sequence[TabularProc]):\n",
    "        self.procs = procs\n",
    "        self.isset = False\n",
    "    def setup(self, data):\n",
    "        for proc in self.procs:\n",
    "            proc.setup(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Normalize(TabularProc):\n",
    "    \"\"\"\n",
    "    Normalizes continuous features to zero mean and unit variance.\n",
    "    \"\"\"\n",
    "    def setup(self, df:pd.DataFrame, cont_names:Sequence):\n",
    "        \"\"\"Store mean and std for columns in cont_names\"\"\"\n",
    "        self.checkup()\n",
    "        self.mean = {col: df[col].mean() for col in cont_names}\n",
    "        self.std = {col: df[col].std() for col in cont_names}\n",
    "        self.is_set = True\n",
    "    \n",
    "    def encode_one(self, df:pd.DataFrame, col:str):\n",
    "        return (df[col] - self.mean[col])/self.std[col]\n",
    "\n",
    "    def encode(self, df:pd.DataFrame, cont_names:Sequence):\n",
    "        for col in cont_names:\n",
    "            df[col] = self.encode_one(df, col)\n",
    "    \n",
    "    def decode_one(self, df:pd.DataFrame, col:str):\n",
    "        return df[col]*self.std[col] + self.mean[col]\n",
    "    \n",
    "    def decode(self, df:pd.DataFrame, cont_names:Sequence):\n",
    "        for col in cont_names:\n",
    "            df[col] = self.decode_one(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(df, cont_names=cont_names):\n",
    "    for col in cont_names:\n",
    "        print(f'{col}: mean= {df[col].mean():.4f}, std = {df[col].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "norm.setup(test_df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_0: mean= -1.6134, std = 2.5976\n",
      "cont_1: mean= 4.8120, std = 2.7086\n",
      "cont_2: mean= -1.8440, std = 2.4517\n",
      "cont_3: mean= 2.8474, std = 1.4774\n",
      "cont_4: mean= 3.6936, std = 2.9721\n"
     ]
    }
   ],
   "source": [
    "print_stat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.encode(test_df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_0: mean= 0.0000, std = 1.0000\n",
      "cont_1: mean= 0.0000, std = 1.0000\n",
      "cont_2: mean= -0.0000, std = 1.0000\n",
      "cont_3: mean= 0.0000, std = 1.0000\n",
      "cont_4: mean= -0.0000, std = 1.0000\n"
     ]
    }
   ],
   "source": [
    "print_stat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_df[cont_names].mean():\n",
    "    assert isclose(x, 0, abs_tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_df[cont_names].std():\n",
    "    assert isclose(x, 1, abs_tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.decode(test_df, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_0: mean= -1.6134, std = 2.5976\n",
      "cont_1: mean= 4.8120, std = 2.7086\n",
      "cont_2: mean= -1.8440, std = 2.4517\n",
      "cont_3: mean= 2.8474, std = 1.4774\n",
      "cont_4: mean= 3.6936, std = 2.9721\n"
     ]
    }
   ],
   "source": [
    "print_stat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (test_df[cont_names] - df[cont_names]).abs().sum():\n",
    "    assert x < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FillMissing proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class FillMissing(TabularProc):\n",
    "    \"\"\"Fills missing values in continuous columns\"\"\"\n",
    "    def __init__(self, add_bool=True, method='mean'):\n",
    "        self.add_bool = add_bool\n",
    "        self.method = method\n",
    "        \n",
    "    def setup(self, df:pd.DataFrame, cont_names:Sequence, cat_names:Sequence):\n",
    "        self.checkup()\n",
    "        if self.method == 'mean':\n",
    "            self.values = {col:df[col].mean() for col in cont_names}\n",
    "        self.cont_names = cont_names\n",
    "        self.cat_names = cat_names\n",
    "        self.isset = True\n",
    "        \n",
    "    def encode(self, df:pd.DataFrame, cont_names:Sequence=None):\n",
    "        if not cont_names:\n",
    "            cont_names = self.cont_names\n",
    "        for col in cont_names:\n",
    "            if not df[col].isna().any():\n",
    "                continue\n",
    "            if self.add_bool:\n",
    "                df[f'{col}_na'] = df[col].isna().astype(np.int8)\n",
    "            df[col].fillna(value=self.values[col], inplace=True)\n",
    "            \n",
    "    def decode(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   891 non-null    float64\n",
      " 6   cat_1   902 non-null    float64\n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), float64(2)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(nons=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillproc = FillMissing()\n",
    "fillproc.setup(test_df, cont_names, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillproc.encode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   cont_0     1000 non-null   float32\n",
      " 1   cont_1     1000 non-null   float32\n",
      " 2   cont_2     1000 non-null   float32\n",
      " 3   cont_3     1000 non-null   float32\n",
      " 4   cont_4     1000 non-null   float32\n",
      " 5   cat_0      891 non-null    float64\n",
      " 6   cat_1      902 non-null    float64\n",
      " 7   targ       1000 non-null   float32\n",
      " 8   cont_0_na  1000 non-null   int8   \n",
      " 9   cont_1_na  1000 non-null   int8   \n",
      " 10  cont_2_na  1000 non-null   int8   \n",
      " 11  cont_3_na  1000 non-null   int8   \n",
      " 12  cont_4_na  1000 non-null   int8   \n",
      "dtypes: float32(6), float64(2), int8(5)\n",
      "memory usage: 44.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cont_names:\n",
    "    assert not df[cont_names].isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorify proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _catlist(s:pd.Series):\n",
    "    c = set(s)\n",
    "    c.discard('#na')\n",
    "    return ['#na'] + list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorify(TabularProc):\n",
    "    \"\"\"Numericalizes categorical columns.\"\"\"\n",
    "    def setup(self, df:pd.DataFrame, cat_names:Sequence):\n",
    "        self.checkup()\n",
    "        self.cat = {col: _catlist(df[col].dropna()) for col in cat_names}\n",
    "        self.i2c = {c: i for i, c in enumerate(self.cat)}\n",
    "\n",
    "    def encode_one(self, df:pd.DataFrame, col:str):\n",
    "        return pd.Series(pd.Categorical(test_df[col].fillna('#na'), categories=self.cat[col])).cat.codes\n",
    "    \n",
    "    def encode(self, df:pd.DataFrame, cat_names:Sequence):\n",
    "        for col in cat_names:\n",
    "            df[col] = self.encode_one(df, col)\n",
    "    \n",
    "    def decode_one(self, df:pd.DataFrame, col:str):\n",
    "        return pd.Series(pd.Categorical.from_codes(df[col], categories=self.cat[col]))\n",
    "    \n",
    "    def decode(self, df:pd.DataFrame, cat_names:Sequence):\n",
    "        for col in cat_names:\n",
    "            df[col] = self.decode_one(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   891 non-null    object \n",
      " 6   cat_1   901 non-null    object \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), object(2)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df, cont_names, cat_names = fake_data(preproc=False, nons=True)\n",
    "test_df = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cproc = Categorify()\n",
    "cproc.setup(test_df, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_0': ['#na', 'A', 'C', 'B'], 'cat_1': ['#na', 'A', 'C', 'B']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cproc.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cproc.encode(test_df, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cont_0  883 non-null    float32\n",
      " 1   cont_1  899 non-null    float32\n",
      " 2   cont_2  912 non-null    float32\n",
      " 3   cont_3  902 non-null    float32\n",
      " 4   cont_4  894 non-null    float32\n",
      " 5   cat_0   1000 non-null   int8   \n",
      " 6   cat_1   1000 non-null   int8   \n",
      " 7   targ    1000 non-null   float32\n",
      "dtypes: float32(6), int8(2)\n",
      "memory usage: 25.5 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_names:\n",
    "    assert sum(test_df.loc[df[col].isna(), col]) == 0\n",
    "    assert np.issubdtype(test_df[col].dtype, np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cproc.decode(test_df, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_names:\n",
    "    assert (df.loc[df[col].notna(), col] == test_df.loc[df[col].notna(), col]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cont_cat_split(df, dep_var=None, max_card=np.inf):\n",
    "    cont, cat = [], []\n",
    "    for col in df.columns:\n",
    "        if col == dep_var: continue #?? mb change to support multiple dep var\n",
    "        if np.issubdtype(df[col].dtype, np.floating) or (len(df[col].unique()) > max_card and np.issubdtype(df[col].dtype, np.integer)):\n",
    "            cont.append(col)\n",
    "        else: #?? any condition np.issubdtype(df[col].dtype, np.integer) \n",
    "            cat.append(col)\n",
    "    return cont, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df:pd.DataFrame, cat_names:Sequence, cont_names:Sequence, dep_var:Sequence, procs=None):\n",
    "        self.data = df\n",
    "        self.cat = cat_names\n",
    "        self.cont = cont_names\n",
    "        self.dep_var = dep_var\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[self.cat].iloc[idx].to_numpy(dtype=np.long), \n",
    "                self.data[self.cont].iloc[idx].to_numpy(dtype=np.float32), \n",
    "                self.data[self.dep_var].iloc[idx].to_numpy(dtype=np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dsets(df:pd.DataFrame, cat_names:Sequence, cont_names:Sequence, dep_var:Sequence, splits=None, stratify=True):\n",
    "    if splits:\n",
    "        train_df, valid_df = df[splits[0]], df[splits[1]]\n",
    "    else:\n",
    "        s = df[dep_var[0]] if stratify else None\n",
    "        train_df, valid_df = train_test_split(df, test_size=0.2, stratify=s)\n",
    "    return (TabularDataset(train_df, cat_names, cont_names, dep_var), \n",
    "            TabularDataset(valid_df, cat_names, cont_names, dep_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dl(ds, bs=512, train=True, drop_last=True):\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=train, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00a_test_utils.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
