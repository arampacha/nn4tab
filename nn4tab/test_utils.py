# AUTOGENERATED! DO NOT EDIT! File to edit: 00a_test_utils.ipynb (unless otherwise specified).

__all__ = ['cont_cat_split', 'fake_data', 'test_normalized', 'test_nans', 'test_categorical', 'test_df_processed']

# Cell
import numpy as np
import pandas as pd
from collections import namedtuple
from pathlib import Path
import random
from math import isclose
import string
import pdb

# Cell
def cont_cat_split(df, dep_var=None, max_card=np.inf, ignore=[]):
    """
    Sugests a split of columns of the dataframe to continuous and categorical ommiting dep_var and
    ignore. Split is done based on column datatype: float columns and int with cardinality > max_card
    are treated as continuous, all other - categorical.
    """
    cont, cat = [], []
    for col in df.columns:
        if (col == dep_var) or (col in dep_var) or (col in ignore): continue
        if np.issubdtype(df[col].dtype, np.floating) or (len(df[col].unique()) > max_card and np.issubdtype(df[col].dtype, np.integer)):
            cont.append(col)
        else: #?? any condition np.issubdtype(df[col].dtype, np.integer)
            cat.append(col)
    return cont, cat

# Cell
def fake_data(n=1000, n_cont=5, n_cat=2, task='class', preproc=True, nans=False):
    """
    Generates randomized tabular dataframe conatining:
    n samples, n_cont continious features, n_cat categorical features.
    If preproc is True, continious values are normalized and categorical features
    are numericalized.
    If nans is True, some NoN values are added randomly
    """
    rng = np.random.default_rng(8)

    loc = 0. if preproc else rng.uniform(-5, 5, size=(n_cont,))
    scale = 1. if preproc else rng.uniform(1, 5, size=(n_cont,))
    cont = rng.normal(loc, scale, size=(n, n_cont))

    #mb change to support varying cardinality through categories
    cat = rng.integers(3, size=(n, n_cat))
    a = np.array(list(string.ascii_uppercase))
    cat_data = cat if preproc else a[cat]

    cont_names = [f'cont_{i}' for i in range(n_cont)]
    cat_names = [f'cat_{i}' for i in range(n_cat)]


    cont_data = np.where((rng.uniform(size=cont.shape) > 0.9), np.nan, cont) if nans else cont
#         cat_data = np.where((rng.uniform(size=cat_data.shape) > 0.9), np.nan, cat_data)

    left = pd.DataFrame(cont_data, columns=cont_names, dtype=np.float32)
    right = pd.DataFrame(cat_data, columns=cat_names)
    df = left.join(right)

    if nans:
        for col in cat_names:
            df.loc[(rng.uniform(size=len(df[col])) > 0.9), col] = np.nan

    df['targ'] = cont.sum(axis=1) + cat.sum(axis=1) - 1

    if task=='class':
        df['targ'] = (df['targ']>df['targ'].mean()).astype(np.float32)

    return df, cont_names, cat_names

# Cell
def test_normalized(df, cont_names):
    """Test if all columns in cont_names of the dataframe are close to standard normal"""
    for m in df[cont_names].mean():
        assert isclose(m, 0, abs_tol=0.2), f'mean is {m}'
    for s in df[cont_names].std():
        assert isclose(s, 1, abs_tol=0.2), f'std is {s}'

# Cell
def test_nans(df, cont_names, cat_names):
    assert df[cont_names].notna().all().all(), 'There are NaNs in continiuous columns'
    assert df[cat_names].notna().all().all(), 'There are NaNs in categorical columns'

# Cell
def test_categorical(df, cat_names):
    for col in cat_names:
        assert np.issubdtype(df[col].dtype, np.integer), f'{col} dtype is not int'

# Cell
def test_df_processed(df, cont_names=[], cat_names=[], dep_var=[]):
    if not dep_var: dep_var = ['targ']
    if not (cont_names or cat_names):
        cont_names, cat_names = cont_cat_split(df, dep_var=dep_var)
    test_normalized(df, cont_names)
    test_nans(df, cont_names, cat_names)
    test_categorical(df, cat_names)